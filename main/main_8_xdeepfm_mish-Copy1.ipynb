{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "# ---------------------------------\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tqdm\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from hyperopt import hp\n",
    "from deepctr.models import xDeepFM\n",
    "from deepctr.inputs import  SparseFeat, DenseFeat, get_feature_names\n",
    "# ---------------------------------\n",
    "from tools import CV, Tuning, CVGetScore, IdxValEncoder, LE, CyclicLR, MaxLrFinder\n",
    "# ---------------------------------\n",
    "from tools import focal_loss, gelu, mish\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'focal_loss': focal_loss()})\n",
    "get_custom_objects().update({'mish': mish})\n",
    "get_custom_objects().update({'gelu': gelu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', index_col='id')\n",
    "test_df = pd.read_csv('../data/test.csv', index_col='id')\n",
    "\n",
    "# ord_5\n",
    "for i in range(2):\n",
    "    train_df[f'ord_5_{i}'] = train_df['ord_5'].str[i]\n",
    "    test_df[f'ord_5_{i}'] = test_df['ord_5'].str[i]\n",
    "\n",
    "# null\n",
    "train_df['null'] = train_df.isna().sum(axis=1)\n",
    "test_df['null'] = test_df.isna().sum(axis=1)\n",
    "\n",
    "for col in test_df.columns:\n",
    "    train_df[col].fillna('isnull', inplace=True)\n",
    "    test_df[col].fillna('isnull', inplace=True)\n",
    "\n",
    "# target\n",
    "target = train_df['target']\n",
    "y_train = target.values\n",
    "\n",
    "# drop\n",
    "train_df.drop(['target', 'ord_5'], axis=1, inplace=True)\n",
    "test_df.drop(['ord_5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = train_df.columns\n",
    "\n",
    "bin_col = ['null']\n",
    "\n",
    "class_col = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4',\n",
    "             'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4',\n",
    "             'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
    "             'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4',\n",
    "             'day', 'month', 'ord_5_0', 'ord_5_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [00:09, 62562.61it/s]\n",
      "400000it [00:06, 61641.16it/s]\n",
      "600000it [00:09, 60983.68it/s]\n",
      "400000it [00:06, 60945.46it/s]\n"
     ]
    }
   ],
   "source": [
    "ecd = LE(feature_col, bin_col=bin_col, class_col=class_col)\n",
    "\n",
    "ecd.fit(train_df, verbose=1)\n",
    "ecd.fit(test_df, verbose=1)\n",
    "\n",
    "x_train_arr = ecd.transform(train_df, verbose=1)\n",
    "x_test_arr = ecd.transform(test_df, verbose=1)\n",
    "\n",
    "del train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_df = pd.DataFrame(data=x_train_arr, columns=feature_col)\n",
    "# x_test_df = pd.DataFrame(data=x_test_arr, columns=feature_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_func(vocabulary, sparse_features, dense_features, k=5):\n",
    "    # sparse\n",
    "    feature_col = list()\n",
    "    for f in sparse_features:\n",
    "        feature_col.append(SparseFeat(f, vocabulary_size=vocabulary[f], embedding_dim=k))\n",
    "    for f in dense_features:\n",
    "        feature_col.append(DenseFeat(f, 1))\n",
    "\n",
    "    dnn_f = feature_col\n",
    "    linear_f= feature_col\n",
    "    fn = get_feature_names(linear_f + dnn_f)\n",
    "    return dnn_f, linear_f, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xdeepfm(vocabulary, k, loss, metrics, optimizer, \n",
    "            num_deep_layer=2, num_neuron=256,\n",
    "            num_cin_layer=2, num_cin=128,**kwargs):\n",
    "    \n",
    "    dnn_f, linear_f, _ = col_func(vocabulary, sparse_features=class_col, dense_features=bin_col, k=k)\n",
    "    tf.random.set_seed(1024)\n",
    "    model = xDeepFM(linear_feature_columns=linear_f,\n",
    "                    dnn_feature_columns=dnn_f, \n",
    "                    cin_layer_size=tuple(num_cin for _ in range(num_cin_layer)),\n",
    "                    dnn_hidden_units=tuple(num_neuron for _ in range(num_deep_layer)),\n",
    "                    **kwargs)\n",
    "    model.compile(loss=loss, metrics=metrics, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkinput(input_arr, feature_col):\n",
    "    return dict(zip(feature_col, input_arr.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 4293006264\n",
    "log = pd.read_csv(f'/data/{seed}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = {key: list(val.values())[0] for key, val in log.sort_values('score').head(1).to_dict().items()}\n",
    "\n",
    "model_fix_param = {'vocabulary': ecd.get_vocabulary(),\n",
    "                   'loss': 'binary_crossentropy',\n",
    "                   'metrics': ['AUC'], \n",
    "                   'optimizer': 'Adam',\n",
    "                   'dnn_activation': 'mish', \n",
    "                   'cin_activation': 'linear',\n",
    "                   'dnn_use_bn': False, \n",
    "                   'num_deep_layer': 2, \n",
    "                   'num_neuron': 256, \n",
    "                   'num_cin_layer': 2}\n",
    "\n",
    "model_params = dict(list(model_fix_param.items()) + list(model_param.items()))\n",
    "\n",
    "for col in ['score', 'update', 'usetime', 'index']:\n",
    "    model_params.pop(col, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "def fit(model, epoch=100, batch_size=8192):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 479999 samples, validate on 120001 samples\n",
      "475136/479999 [============================>.] - ETA: 0s - loss: 0.5661 - AUC: 0.5081{'loss': 0.5651751996192338, 'AUC': 0.5083667, 'val_loss': 0.4820566004521102, 'val_AUC': 0.59295774}\n",
      "479999/479999 [==============================] - 9s 19us/sample - loss: 0.5652 - AUC: 0.5084 - val_loss: 0.4821 - val_AUC: 0.5930\n",
      "folds 0 is done, score is 0.6022806690894351\n",
      "Train on 479999 samples, validate on 120001 samples\n",
      "475136/479999 [============================>.] - ETA: 0s - loss: 0.5481 - AUC: 0.5154{'loss': 0.5474055043155185, 'AUC': 0.51593757, 'val_loss': 0.47879523168925353, 'val_AUC': 0.68151796}\n",
      "479999/479999 [==============================] - 12s 24us/sample - loss: 0.5474 - AUC: 0.5159 - val_loss: 0.4788 - val_AUC: 0.6815\n",
      "folds 1 is done, score is 0.6848844192161267\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "475136/480000 [============================>.] - ETA: 0s - loss: 0.5355 - AUC: 0.5260{'loss': 0.5348775791168213, 'AUC': 0.5268373, 'val_loss': 0.4759395409107208, 'val_AUC': 0.73556644}\n",
      "480000/480000 [==============================] - 11s 22us/sample - loss: 0.5349 - AUC: 0.5268 - val_loss: 0.4759 - val_AUC: 0.7356\n",
      "folds 2 is done, score is 0.7398930147157022\n",
      "Train on 480001 samples, validate on 119999 samples\n",
      "475136/480001 [============================>.] - ETA: 0s - loss: 0.5299 - AUC: 0.5318{'loss': 0.5293209609775374, 'AUC': 0.5325676, 'val_loss': 0.47424418528558476, 'val_AUC': 0.74315923}\n",
      "480001/480001 [==============================] - 11s 23us/sample - loss: 0.5293 - AUC: 0.5326 - val_loss: 0.4742 - val_AUC: 0.7432\n",
      "folds 3 is done, score is 0.746228401399702\n",
      "Train on 480001 samples, validate on 119999 samples\n",
      "475136/480001 [============================>.] - ETA: 0s - loss: 0.5271 - AUC: 0.5344{'loss': 0.5265096056465208, 'AUC': 0.5351275, 'val_loss': 0.47307849207348945, 'val_AUC': 0.74306166}\n",
      "480001/480001 [==============================] - 11s 23us/sample - loss: 0.5265 - AUC: 0.5351 - val_loss: 0.4731 - val_AUC: 0.7431\n",
      "folds 4 is done, score is 0.7458381322261116\n"
     ]
    }
   ],
   "source": [
    "batch_size=8192\n",
    "epochs=1\n",
    "nflod=5\n",
    "base_lr=3.5\n",
    "max_lr=4.5\n",
    "verbose=1\n",
    "\n",
    "\n",
    "clr = CyclicLR(base_lr=0.1**(base_lr),\n",
    "               max_lr = 0.1**(max_lr), \n",
    "               step_size= int(4.0*(x_train_arr.shape[0]*((nflod-1)/nflod)) / batch_size),\n",
    "               mode='triangular2',\n",
    "               gamma=1.0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', patience=2, mode='max', restore_best_weights=True)\n",
    "sw = SampleWeight()\n",
    "\n",
    "fit_param = {'batch_size': batch_size, 'epochs':epochs, 'verbose': verbose, 'callbacks':[es, clr, sw]}\n",
    "\n",
    "model = xdeepfm(**model_params)\n",
    "\n",
    "cv = CV(model, nflod)\n",
    "\n",
    "score = cv.fit(x=mkinput(x_train_arr, feature_col),\n",
    "               y=y_train,\n",
    "               metrics_func=roc_auc_score,\n",
    "               split_method=StratifiedKFold,\n",
    "               fit_params=fit_param,\n",
    "               eval_param={'batch_size':batch_size},\n",
    "               use_proba=False, \n",
    "               verbose=verbose,\n",
    "               fit_use_valid=True)\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'sample_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-aaff50c3a2bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'sample_weight'"
     ]
    }
   ],
   "source": [
    "cv.model[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
