{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# target encoder & ohe & DeepFM - predict - stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "# ---------------------------------\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp\n",
    "# ---------------------------------\n",
    "from tools import CV, Tuning, CVGetScore, IdxValEncoder, deepfm, CyclicLR, MaxLrFinder\n",
    "# ---------------------------------\n",
    "from tools import focal_loss, gelu, mish\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'focal_loss': focal_loss()})\n",
    "get_custom_objects().update({'mish': mish})\n",
    "get_custom_objects().update({'gelu': gelu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', index_col='id')\n",
    "test_df = pd.read_csv('../data/test.csv', index_col='id')\n",
    "\n",
    "# ord_5\n",
    "for i in range(2):\n",
    "    train_df[f'ord_5_{i}'] = train_df['ord_5'].str[i]\n",
    "    test_df[f'ord_5_{i}'] = test_df['ord_5'].str[i]\n",
    "\n",
    "# null\n",
    "train_df['null'] = train_df.isna().sum(axis=1)\n",
    "test_df['null'] = test_df.isna().sum(axis=1)\n",
    "\n",
    "for col in test_df.columns:\n",
    "    train_df[col].fillna('isnull', inplace=True)\n",
    "    test_df[col].fillna('isnull', inplace=True)\n",
    "\n",
    "# target\n",
    "target = train_df['target']\n",
    "y_train = target.values\n",
    "\n",
    "# drop\n",
    "train_df.drop(['target', 'ord_5'], axis=1, inplace=True)\n",
    "test_df.drop(['ord_5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = train_df.columns\n",
    "\n",
    "bin_col = ['null']\n",
    "\n",
    "class_col = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4',\n",
    "             'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4',\n",
    "             'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
    "             'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4',\n",
    "             'day', 'month', 'ord_5_0', 'ord_5_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in bin_col:\n",
    "#     map_dict = dict(zip(train_df[col].unique(), [0., 1.]))\n",
    "#     train_df[col] = train_df[col].map(map_dict)\n",
    "#     test_df[col] = test_df[col].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [00:10, 55411.43it/s]\n"
     ]
    }
   ],
   "source": [
    "ecd = IdxValEncoder(feature_col, bin_col=bin_col, class_col=class_col)\n",
    "ecd.fit(train_df, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:07, 53877.34it/s]\n"
     ]
    }
   ],
   "source": [
    "ecd.fit(test_df, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [00:12, 46665.01it/s]\n",
      "400000it [00:08, 46405.70it/s]\n"
     ]
    }
   ],
   "source": [
    "idx, val = ecd.transform(train_df, verbose=1)\n",
    "idx_test, val_test = ecd.transform(test_df, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('../tmp/deepfm/03051921.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>update</th>\n",
       "      <th>usetime</th>\n",
       "      <th>deep_activation</th>\n",
       "      <th>deep_dropout</th>\n",
       "      <th>l2_deep</th>\n",
       "      <th>l2_pair</th>\n",
       "      <th>num_neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.788738</td>\n",
       "      <td>True</td>\n",
       "      <td>184.576666</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.788713</td>\n",
       "      <td>True</td>\n",
       "      <td>161.217921</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.101581</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-0.788669</td>\n",
       "      <td>False</td>\n",
       "      <td>135.140283</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.091591</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.788648</td>\n",
       "      <td>False</td>\n",
       "      <td>130.189999</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.044670</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-0.788645</td>\n",
       "      <td>False</td>\n",
       "      <td>180.608015</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.788643</td>\n",
       "      <td>False</td>\n",
       "      <td>171.826066</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.128133</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.788623</td>\n",
       "      <td>True</td>\n",
       "      <td>221.660247</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.407878</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.788617</td>\n",
       "      <td>False</td>\n",
       "      <td>194.853450</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.367318</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.788603</td>\n",
       "      <td>False</td>\n",
       "      <td>214.681732</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.118396</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-0.788595</td>\n",
       "      <td>False</td>\n",
       "      <td>224.605684</td>\n",
       "      <td>gelu</td>\n",
       "      <td>0.176778</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  update     usetime deep_activation  deep_dropout   l2_deep  \\\n",
       "37 -0.788738    True  184.576666            gelu      0.036688  0.000039   \n",
       "22 -0.788713    True  161.217921            gelu      0.101581  0.000104   \n",
       "59 -0.788669   False  135.140283            gelu      0.091591  0.000008   \n",
       "40 -0.788648   False  130.189999            gelu      0.044670  0.000012   \n",
       "53 -0.788645   False  180.608015            gelu      0.155234  0.000110   \n",
       "68 -0.788643   False  171.826066            gelu      0.128133  0.000045   \n",
       "13 -0.788623    True  221.660247            gelu      0.407878  0.000107   \n",
       "85 -0.788617   False  194.853450            gelu      0.367318  0.000006   \n",
       "55 -0.788603   False  214.681732            gelu      0.118396  0.000085   \n",
       "96 -0.788595   False  224.605684            gelu      0.176778  0.000157   \n",
       "\n",
       "     l2_pair  num_neuron  \n",
       "37  0.001919         256  \n",
       "22  0.000939         128  \n",
       "59  0.003207         128  \n",
       "40  0.001696         128  \n",
       "53  0.000710         256  \n",
       "68  0.001630         128  \n",
       "13  0.001208         256  \n",
       "85  0.002529         256  \n",
       "55  0.001304         256  \n",
       "96  0.000690         256  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.sort_values('score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8192\n",
    "epochs = 200\n",
    "nflod = 20\n",
    "nmodel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "model_tuning_param = log.sort_values('score').head(nmodel).reset_index(drop=True).to_dict()\n",
    "\n",
    "model_fix_param = {'vocabulary_size':ecd.get_vocabulary(), \n",
    "                   'feature_number': len(feature_col),\n",
    "                   'activation': 'sigmoid',\n",
    "                   'metrics': ['AUC'],\n",
    "                   'use_fm': True,\n",
    "                   'k': 5,\n",
    "                   'deep_use_bn': False,\n",
    "                   'optimizer': 'Adam',\n",
    "                   'loss': 'binary_crossentropy',\n",
    "                   'num_deep_layer':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "clr = CyclicLR(\n",
    "    base_lr=1e-5,\n",
    "    max_lr = 1e-4, \n",
    "    step_size= int(4.0*(train_df.shape[0]*((nflod-1)/nflod)) / batch_size),\n",
    "    mode='exp_range',\n",
    "    gamma=1.0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', \n",
    "                                      patience=3,\n",
    "                                      mode='max',\n",
    "                                      restore_best_weights=True)\n",
    "\n",
    "# fit\n",
    "fit_param = {\n",
    "    'batch_size': batch_size, \n",
    "    'epochs':epochs, \n",
    "    'verbose': 0,\n",
    "    'callbacks':[es, clr]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folds 0 is done, score is 0.7860738197447208\n",
      "folds 1 is done, score is 0.789516510902717\n",
      "folds 2 is done, score is 0.7913933436689137\n",
      "folds 3 is done, score is 0.7897472716334469\n",
      "folds 4 is done, score is 0.786214431863218\n",
      "folds 5 is done, score is 0.7943257075128896\n",
      "folds 6 is done, score is 0.7890275724331868\n",
      "folds 7 is done, score is 0.7882536416680219\n",
      "folds 8 is done, score is 0.7912310396546987\n",
      "folds 9 is done, score is 0.7950927155656691\n",
      "folds 10 is done, score is 0.7881046061858787\n",
      "folds 11 is done, score is 0.7859464469485385\n",
      "folds 12 is done, score is 0.7855004723801886\n",
      "folds 13 is done, score is 0.7879865403484888\n",
      "folds 14 is done, score is 0.7920841471171606\n",
      "folds 15 is done, score is 0.7893588220300921\n",
      "folds 16 is done, score is 0.7897881506882285\n",
      "folds 17 is done, score is 0.7935690075134796\n",
      "folds 18 is done, score is 0.7847190761641609\n",
      "folds 19 is done, score is 0.7870710119153563\n",
      "score:  0.7892502167969526\n",
      "folds 0 is done, score is 0.786082166432755\n",
      "folds 1 is done, score is 0.7896454865843091\n",
      "folds 2 is done, score is 0.7914860956007301\n",
      "folds 3 is done, score is 0.7897804320099677\n",
      "folds 4 is done, score is 0.7861950219797578\n",
      "folds 5 is done, score is 0.7945727125196757\n",
      "folds 6 is done, score is 0.7889706827804044\n",
      "folds 7 is done, score is 0.7881917973102254\n",
      "folds 8 is done, score is 0.7913374617527443\n",
      "folds 9 is done, score is 0.7951099821832166\n",
      "folds 10 is done, score is 0.7880015322562176\n",
      "folds 11 is done, score is 0.7859275993528988\n",
      "folds 12 is done, score is 0.7856341398789828\n",
      "folds 13 is done, score is 0.7880896252318086\n",
      "folds 14 is done, score is 0.7918581074133897\n",
      "folds 15 is done, score is 0.7895016906023099\n",
      "folds 16 is done, score is 0.7901091659165601\n",
      "folds 17 is done, score is 0.7936282623384401\n",
      "folds 18 is done, score is 0.7846964088480264\n",
      "folds 19 is done, score is 0.787190200599067\n",
      "score:  0.7893004285795743\n",
      "folds 0 is done, score is 0.7859276103065574\n",
      "folds 1 is done, score is 0.7892619369176743\n",
      "folds 2 is done, score is 0.7912535676797078\n",
      "folds 3 is done, score is 0.7898376940871507\n",
      "folds 4 is done, score is 0.7861428204929579\n",
      "folds 5 is done, score is 0.7942060241852114\n",
      "folds 6 is done, score is 0.7889812749685001\n",
      "folds 7 is done, score is 0.7881094878665008\n",
      "folds 8 is done, score is 0.791171597799407\n",
      "folds 9 is done, score is 0.7951103327002995\n",
      "folds 10 is done, score is 0.787989742468089\n",
      "folds 11 is done, score is 0.7856566167869174\n",
      "folds 12 is done, score is 0.7853882156332022\n",
      "folds 13 is done, score is 0.7878661377305467\n",
      "folds 14 is done, score is 0.7920368857304964\n",
      "folds 15 is done, score is 0.7893360712806866\n",
      "folds 16 is done, score is 0.7896805236877107\n",
      "folds 17 is done, score is 0.7935705444663049\n",
      "folds 18 is done, score is 0.7845845143014775\n",
      "folds 19 is done, score is 0.7868488583445048\n",
      "score:  0.789148022871695\n",
      "folds 0 is done, score is 0.7858702679025431\n",
      "folds 1 is done, score is 0.7893237557169337\n",
      "folds 2 is done, score is 0.7911551782648095\n",
      "folds 3 is done, score is 0.7896837038999933\n",
      "folds 4 is done, score is 0.7859268873650743\n",
      "folds 5 is done, score is 0.7941751020063131\n",
      "folds 6 is done, score is 0.7888654473287326\n",
      "folds 7 is done, score is 0.788081169007186\n",
      "folds 8 is done, score is 0.7910577126084735\n",
      "folds 9 is done, score is 0.7950952056974447\n",
      "folds 10 is done, score is 0.787865495115895\n",
      "folds 11 is done, score is 0.785570696286996\n",
      "folds 12 is done, score is 0.7853177872580965\n",
      "folds 13 is done, score is 0.7877513835493453\n",
      "folds 14 is done, score is 0.7918135953950936\n",
      "folds 15 is done, score is 0.7891828149886713\n",
      "folds 16 is done, score is 0.7896080360247437\n",
      "folds 17 is done, score is 0.7934255305942653\n",
      "folds 18 is done, score is 0.7845856423737412\n",
      "folds 19 is done, score is 0.7868012055054804\n",
      "score:  0.7890578308444915\n",
      "folds 0 is done, score is 0.7862404906175924\n",
      "folds 1 is done, score is 0.7895427266595348\n",
      "folds 2 is done, score is 0.7913772016270066\n",
      "folds 3 is done, score is 0.7898944669009056\n",
      "folds 4 is done, score is 0.7861747759670066\n",
      "folds 5 is done, score is 0.794592845344619\n",
      "folds 6 is done, score is 0.7889643990314512\n",
      "folds 7 is done, score is 0.788018594405467\n",
      "folds 8 is done, score is 0.7911975287610951\n",
      "folds 9 is done, score is 0.7950549035353619\n",
      "folds 10 is done, score is 0.7880351563376293\n",
      "folds 11 is done, score is 0.7858729442465191\n",
      "folds 12 is done, score is 0.7856679684286927\n",
      "folds 13 is done, score is 0.7881927977443992\n",
      "folds 14 is done, score is 0.7917819977405669\n",
      "folds 15 is done, score is 0.7893846215478741\n",
      "folds 16 is done, score is 0.7897928059932346\n",
      "folds 17 is done, score is 0.7935012611154272\n",
      "folds 18 is done, score is 0.7847783747977529\n",
      "folds 19 is done, score is 0.7870920729149988\n",
      "score:  0.7892578966858569\n",
      "folds 0 is done, score is 0.7861391035513924\n",
      "folds 1 is done, score is 0.789624787820326\n",
      "folds 2 is done, score is 0.7913652840461917\n",
      "folds 3 is done, score is 0.7899360141288764\n",
      "folds 4 is done, score is 0.7861362482976553\n",
      "folds 5 is done, score is 0.7943855071877033\n",
      "folds 6 is done, score is 0.7888940984490321\n",
      "folds 7 is done, score is 0.7882012320617041\n",
      "folds 8 is done, score is 0.7912733938022036\n",
      "folds 9 is done, score is 0.7951710962970908\n",
      "folds 10 is done, score is 0.788000436890334\n",
      "folds 11 is done, score is 0.785750507899253\n",
      "folds 12 is done, score is 0.78555925701595\n",
      "folds 13 is done, score is 0.7881728036658011\n",
      "folds 14 is done, score is 0.7919242419542308\n",
      "folds 15 is done, score is 0.7894214514001056\n",
      "folds 16 is done, score is 0.7898401367530714\n",
      "folds 17 is done, score is 0.7935834242039959\n",
      "folds 18 is done, score is 0.7846853216135119\n",
      "folds 19 is done, score is 0.7871765542103232\n",
      "score:  0.7892620450624376\n",
      "folds 0 is done, score is 0.7859868549959901\n",
      "folds 1 is done, score is 0.7895444500351919\n",
      "folds 2 is done, score is 0.7914462169801223\n",
      "folds 3 is done, score is 0.7899529630903175\n",
      "folds 4 is done, score is 0.7862573300424454\n",
      "folds 5 is done, score is 0.794440293737989\n",
      "folds 6 is done, score is 0.7889833086978243\n",
      "folds 7 is done, score is 0.788131241832952\n",
      "folds 8 is done, score is 0.791222302286166\n",
      "folds 9 is done, score is 0.7948118491481968\n",
      "folds 10 is done, score is 0.7880695836873555\n",
      "folds 11 is done, score is 0.7858594639437098\n",
      "folds 12 is done, score is 0.7855615609355253\n",
      "folds 13 is done, score is 0.7880968911588375\n",
      "folds 14 is done, score is 0.7918640150867227\n",
      "folds 15 is done, score is 0.7892360242120844\n",
      "folds 16 is done, score is 0.7899963468817534\n",
      "folds 17 is done, score is 0.7936407916070781\n",
      "folds 18 is done, score is 0.7847476065354914\n",
      "folds 19 is done, score is 0.7870739178879191\n",
      "score:  0.7892461506391837\n",
      "folds 0 is done, score is 0.7860811842546791\n",
      "folds 1 is done, score is 0.7893456958955853\n",
      "folds 2 is done, score is 0.7912430485160042\n",
      "folds 3 is done, score is 0.7897134905495922\n",
      "folds 4 is done, score is 0.786304379658372\n",
      "folds 5 is done, score is 0.794465706226492\n",
      "folds 6 is done, score is 0.7890780614979884\n",
      "folds 7 is done, score is 0.7879838859118304\n",
      "folds 8 is done, score is 0.7912864943781734\n",
      "folds 9 is done, score is 0.7949802032333098\n",
      "folds 10 is done, score is 0.7879427987375309\n",
      "folds 11 is done, score is 0.7857670917387329\n",
      "folds 12 is done, score is 0.785301886196684\n",
      "folds 13 is done, score is 0.7879392899154832\n",
      "folds 14 is done, score is 0.79178677353582\n",
      "folds 15 is done, score is 0.7893101001555829\n",
      "folds 16 is done, score is 0.7898744071003545\n",
      "folds 17 is done, score is 0.7934093725106429\n",
      "folds 18 is done, score is 0.7846321707912213\n",
      "folds 19 is done, score is 0.7870369397521282\n",
      "score:  0.7891741490278104\n",
      "folds 0 is done, score is 0.7861112885603844\n",
      "folds 1 is done, score is 0.7894153136999368\n",
      "folds 2 is done, score is 0.7914028879569808\n",
      "folds 3 is done, score is 0.7899132305184942\n",
      "folds 4 is done, score is 0.7862697843525435\n",
      "folds 5 is done, score is 0.7945175827547465\n",
      "folds 6 is done, score is 0.7890162682572666\n",
      "folds 7 is done, score is 0.7882249211745501\n",
      "folds 8 is done, score is 0.7912291994400139\n",
      "folds 9 is done, score is 0.7951436464280439\n",
      "folds 10 is done, score is 0.7880341595546749\n",
      "folds 11 is done, score is 0.7857666353362814\n",
      "folds 12 is done, score is 0.7855894672070238\n",
      "folds 13 is done, score is 0.788056983328473\n",
      "folds 14 is done, score is 0.791957493611242\n",
      "folds 15 is done, score is 0.7893801122916525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folds 16 is done, score is 0.7899782076227183\n",
      "folds 17 is done, score is 0.7935550544643145\n",
      "folds 18 is done, score is 0.7848024877987303\n",
      "folds 19 is done, score is 0.787047665565432\n",
      "score:  0.7892706194961752\n",
      "folds 0 is done, score is 0.7860479472025466\n",
      "folds 1 is done, score is 0.7895519350353977\n",
      "folds 2 is done, score is 0.7914977137815372\n",
      "folds 3 is done, score is 0.7900414723049443\n",
      "folds 4 is done, score is 0.7862170242291429\n",
      "folds 5 is done, score is 0.7944560889140326\n",
      "folds 6 is done, score is 0.7889292596939005\n",
      "folds 7 is done, score is 0.7881996985494668\n",
      "folds 8 is done, score is 0.7911747889653483\n",
      "folds 9 is done, score is 0.7950696289040593\n",
      "folds 10 is done, score is 0.7880324033180415\n",
      "folds 11 is done, score is 0.7857922157808865\n",
      "folds 12 is done, score is 0.7856399416669471\n",
      "folds 13 is done, score is 0.7882466203727071\n",
      "folds 14 is done, score is 0.7917522293470661\n",
      "folds 15 is done, score is 0.7893809009550888\n",
      "folds 16 is done, score is 0.7899655232857846\n",
      "folds 17 is done, score is 0.7935380640166918\n",
      "folds 18 is done, score is 0.7847174077854406\n",
      "folds 19 is done, score is 0.7871117320384301\n",
      "score:  0.7892681298073729\n"
     ]
    }
   ],
   "source": [
    "pred_lst = []\n",
    "score_lst = []\n",
    "pred_arr_lst = []\n",
    "\n",
    "for i in range(nmodel):\n",
    "    model_params = {}\n",
    "    for param_name, param_value in model_fix_param.items():\n",
    "        model_params[param_name] = param_value\n",
    "        \n",
    "    for param_name in model_tuning_param.keys():\n",
    "        if param_name not in ['score', 'update', 'usetime', 'index']:\n",
    "            model_params[param_name] = model_tuning_param[param_name][i]\n",
    "            \n",
    "    # cv\n",
    "    model = deepfm(**model_params)\n",
    "    cv = CV(model, nflod)\n",
    "    \n",
    "    score, pred_arr = cv.fit(x=[idx, val],\n",
    "                             y=y_train, \n",
    "                             metrics_func=roc_auc_score,\n",
    "                             split_method=StratifiedKFold,\n",
    "                             fit_params=fit_param,\n",
    "                             eval_param={'batch_size':batch_size},\n",
    "                             use_proba=False, \n",
    "                             verbose=True,\n",
    "                             fit_use_valid=True,\n",
    "                             output_oof_pred=True)\n",
    "    \n",
    "    pred = cv.predict(x=[idx_test, val_test], pred_param={'batch_size': batch_size})\n",
    "    \n",
    "    pred_lst.append(pred)\n",
    "    score_lst.append(score)\n",
    "    pred_arr_lst.append(pred_arr)\n",
    "    \n",
    "    print('score: ', score)\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7892235489811552"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.7892681298073729+0.7892706194961752+ 0.7892502167969526+0.7893004285795743+ 0.789148022871695+0.7890578308444915+0.7892578966858569+0.7892620450624376+0.7892461506391837+0.7891741490278104)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615107092"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 2**32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_arr = np.array(pred_arr_lst).squeeze().T\n",
    "np.save('../tmp/deepfm/1615107092stacking1.npy', pred_arr)\n",
    "pred_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.array(pred_lst).squeeze().T\n",
    "np.save('../tmp/deepfm/1615107092predict.npy', pred)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11874194, 0.12003708, 0.1162231 , ..., 0.11542787, 0.12152357,\n",
       "        0.12602474],\n",
       "       [0.24645662, 0.25164986, 0.25201955, ..., 0.24638703, 0.24964896,\n",
       "        0.24954316],\n",
       "       [0.14907558, 0.15091169, 0.15238895, ..., 0.15072805, 0.15095451,\n",
       "        0.15080431],\n",
       "       ...,\n",
       "       [0.53353614, 0.53340095, 0.5322024 , ..., 0.53753656, 0.5293952 ,\n",
       "        0.5285688 ],\n",
       "       [0.27679983, 0.27474433, 0.26973158, ..., 0.26627794, 0.27561447,\n",
       "        0.27187088],\n",
       "       [0.19893648, 0.20642264, 0.19504796, ..., 0.19918235, 0.20271268,\n",
       "        0.20293233]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv', index_col='id')\n",
    "submission['target'] = np.mean(pred_lst, axis=0)\n",
    "submission.to_csv('../tmp/submission/main_3_deepfm030601.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
