{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# target encoder & ohe & DeepFM - predict - stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "# ---------------------------------\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Activation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp\n",
    "# ---------------------------------\n",
    "from tools import CV, Tuning, CVGetScore, IdxValEncoder, deepfm, CyclicLR, MaxLrFinder\n",
    "# ---------------------------------\n",
    "from tools import focal_loss, gelu, mish\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'focal_loss': focal_loss()})\n",
    "get_custom_objects().update({'mish': mish})\n",
    "get_custom_objects().update({'gelu': gelu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', index_col='id')\n",
    "test_df = pd.read_csv('../data/test.csv', index_col='id')\n",
    "\n",
    "# ord_5\n",
    "for i in range(2):\n",
    "    train_df[f'ord_5_{i}'] = train_df['ord_5'].str[i]\n",
    "    test_df[f'ord_5_{i}'] = test_df['ord_5'].str[i]\n",
    "\n",
    "# null\n",
    "train_df['null'] = train_df.isna().sum(axis=1)\n",
    "test_df['null'] = test_df.isna().sum(axis=1)\n",
    "\n",
    "for col in test_df.columns:\n",
    "    train_df[col].fillna('isnull', inplace=True)\n",
    "    test_df[col].fillna('isnull', inplace=True)\n",
    "\n",
    "# target\n",
    "target = train_df['target']\n",
    "y_train = target.values\n",
    "\n",
    "# drop\n",
    "train_df.drop(['target', 'ord_5'], axis=1, inplace=True)\n",
    "test_df.drop(['ord_5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = train_df.columns\n",
    "\n",
    "bin_col = ['null']\n",
    "\n",
    "class_col = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4',\n",
    "             'nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4',\n",
    "             'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
    "             'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4',\n",
    "             'day', 'month', 'ord_5_0', 'ord_5_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in bin_col:\n",
    "#     map_dict = dict(zip(train_df[col].unique(), [0., 1.]))\n",
    "#     train_df[col] = train_df[col].map(map_dict)\n",
    "#     test_df[col] = test_df[col].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [00:10, 55284.43it/s]\n"
     ]
    }
   ],
   "source": [
    "ecd = IdxValEncoder(feature_col, bin_col=bin_col, class_col=class_col)\n",
    "ecd.fit(train_df, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:07, 55100.25it/s]\n"
     ]
    }
   ],
   "source": [
    "ecd.fit(test_df, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [00:12, 47288.36it/s]\n",
      "400000it [00:08, 48222.69it/s]\n"
     ]
    }
   ],
   "source": [
    "idx, val = ecd.transform(train_df, verbose=1)\n",
    "idx_test, val_test = ecd.transform(test_df, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('../tmp/deepfm/03051921.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8192\n",
    "epochs = 100\n",
    "nflod = 20\n",
    "nmodel = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model params\n",
    "model_tuning_param = log.sort_values('score').head(nmodel).reset_index(drop=True).to_dict()\n",
    "\n",
    "model_fix_param = {'vocabulary_size':ecd.get_vocabulary(), \n",
    "                   'feature_number': len(feature_col),\n",
    "                   'activation': 'sigmoid',\n",
    "                   'metrics': ['AUC'],\n",
    "                   'use_fm': True,\n",
    "                   'k': 5,\n",
    "                   'deep_use_bn': False,\n",
    "                   'optimizer': 'Adam',\n",
    "                   'loss': 'binary_crossentropy',\n",
    "                   'num_deep_layer':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "clr = CyclicLR(\n",
    "    base_lr=1e-5,\n",
    "    max_lr = 1e-3, \n",
    "    step_size= int(4.0*(train_df.shape[0]*((nflod-1)/nflod)) / batch_size),\n",
    "    mode='exp_range',\n",
    "    gamma=1.0)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', \n",
    "                                      patience=3,\n",
    "                                      mode='max',\n",
    "                                      restore_best_weights=True)\n",
    "\n",
    "# fit\n",
    "fit_param = {\n",
    "    'batch_size': batch_size, \n",
    "    'epochs':epochs, \n",
    "    'verbose': 1,\n",
    "    'callbacks':[es, clr]\n",
    "}\n",
    "\n",
    "cv_fit_param = {\n",
    "    'fit_params': fit_param, \n",
    "    'eval_param': {'batch_size':batch_size},\n",
    "    'use_proba':False, \n",
    "    'fit_use_valid': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_lst = []\n",
    "score_lst = []\n",
    "pred_arr_lst = []\n",
    "\n",
    "for i in range(nmodel):\n",
    "    model_params = {}\n",
    "    for param_name, param_value in model_fix_param.items():\n",
    "        model_params[param_name] = param_value\n",
    "        \n",
    "    for param_name in model_tuning_param.keys():\n",
    "        if param_name not in ['score', 'update', 'usetime', 'index']:\n",
    "            model_params[param_name] = model_tuning_param[param_name][i]\n",
    "            \n",
    "    # cv\n",
    "    model = deepfm(**model_params)\n",
    "    cv = CV(model, nflod)\n",
    "    \n",
    "    score, pred_arr = cv.fit(x=[idx, val],\n",
    "                             y=y_train, \n",
    "                             metrics_func=roc_auc_score,\n",
    "                             split_method=StratifiedKFold,\n",
    "                             fit_params=fit_param,\n",
    "                             eval_param={'batch_size':batch_size},\n",
    "                             use_proba=False, \n",
    "                             verbose=True,\n",
    "                             fit_use_valid=True,\n",
    "                             output_oof_pred=True)\n",
    "    \n",
    "    pred = cv.predict(x=[idx_test, val_test], pred_param={'batch_size': batch_size})\n",
    "    pred_lst.append(pred)\n",
    "    score_lst.append(score)\n",
    "    pred_arr_lst.append(pred_arr)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv', index_col='id')\n",
    "submission['target'] = np.mean(pred_lst, axis=0)\n",
    "submission.to_csv('../tmp/submission/main_3_deepfm030601.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
