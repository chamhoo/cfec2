{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# target encoder & ohe & FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "# ---------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from hyperopt import hp\n",
    "# ---------------------------------\n",
    "from tools import CV, Tuning, CVGetScore, IdxValEncoder, fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv', index_col='id')\n",
    "test_df = pd.read_csv('../data/test.csv', index_col='id')\n",
    "\n",
    "# ord_5\n",
    "for i in range(2):\n",
    "    train_df[f'ord_5_{i}'] = train_df['ord_5'].str[i]\n",
    "    test_df[f'ord_5_{i}'] = test_df['ord_5'].str[i]\n",
    "\n",
    "# fillna\n",
    "for col in test_df.columns:\n",
    "    train_df[col].fillna(train_df[col].mode()[0], inplace=True)\n",
    "    test_df[col].fillna(test_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# target\n",
    "target = train_df['target']\n",
    "y_train = target.values\n",
    "\n",
    "# drop\n",
    "train_df.drop(['target', 'ord_5'], axis=1, inplace=True)\n",
    "test_df.drop(['ord_5'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col = train_df.columns\n",
    "\n",
    "bin_col = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\n",
    "\n",
    "class_col = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4',\n",
    "             'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9',\n",
    "             'ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4',\n",
    "             'day', 'month', 'ord_5_0', 'ord_5_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bin_col:\n",
    "    map_dict = dict(zip(train_df[col].unique(), [0., 1.]))\n",
    "    train_df[col] = train_df[col].map(map_dict)\n",
    "    test_df[col] = test_df[col].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [00:11, 52322.58it/s]\n"
     ]
    }
   ],
   "source": [
    "ecd = IdxValEncoder(feature_col, bin_col, class_col)\n",
    "ecd.fit(train_df, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600000it [00:12, 48506.24it/s]\n"
     ]
    }
   ],
   "source": [
    "idx, val = ecd.transform(train_df, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit param\n",
    "batch_size = 8192\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', patience=2, mode='max')\n",
    "fit_param = {'batch_size': batch_size,\n",
    "             'epochs':10,\n",
    "             'verbose': 1, \n",
    "             'callbacks':[callback]}\n",
    "\n",
    "# model_param\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "\n",
    "model_param = {'vocabulary_size':ecd.get_vocabulary(), \n",
    "               'feature_number': len(feature_col),\n",
    "               'activation': 'sigmoid',\n",
    "               'metrics': ['AUC'],\n",
    "               'optimizer': opt, \n",
    "               'k': 5, 'loss': tf.keras.losses.BinaryCrossentropy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fm(**model_param)\n",
    "cv = CV(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/10\n",
      "480000/480000 [==============================] - 3s 6us/sample - loss: 0.6052 - AUC: 0.5123 - val_loss: 0.5464 - val_AUC: 0.5281\n",
      "Epoch 2/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.5166 - AUC: 0.5304 - val_loss: 0.4945 - val_AUC: 0.5681\n",
      "Epoch 3/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4820 - AUC: 0.6252 - val_loss: 0.4705 - val_AUC: 0.6982\n",
      "Epoch 4/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4557 - AUC: 0.7430 - val_loss: 0.4431 - val_AUC: 0.7570\n",
      "Epoch 5/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.4298 - AUC: 0.7699 - val_loss: 0.4238 - val_AUC: 0.7700\n",
      "Epoch 6/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4141 - AUC: 0.7812 - val_loss: 0.4140 - val_AUC: 0.7766\n",
      "Epoch 7/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.4058 - AUC: 0.7875 - val_loss: 0.4092 - val_AUC: 0.7798\n",
      "Epoch 8/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.4012 - AUC: 0.7910 - val_loss: 0.4066 - val_AUC: 0.7817\n",
      "Epoch 9/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3984 - AUC: 0.7930 - val_loss: 0.4053 - val_AUC: 0.7825\n",
      "Epoch 10/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3965 - AUC: 0.7944 - val_loss: 0.4044 - val_AUC: 0.7828\n",
      "folds 0 is done, score is 0.7828379608215226\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/10\n",
      "480000/480000 [==============================] - 3s 5us/sample - loss: 0.5198 - AUC: 0.5375 - val_loss: 0.4596 - val_AUC: 0.7264\n",
      "Epoch 2/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4316 - AUC: 0.7602 - val_loss: 0.4164 - val_AUC: 0.7742\n",
      "Epoch 3/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4063 - AUC: 0.7857 - val_loss: 0.4073 - val_AUC: 0.7814\n",
      "Epoch 4/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3994 - AUC: 0.7918 - val_loss: 0.4047 - val_AUC: 0.7831\n",
      "Epoch 5/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.3962 - AUC: 0.7944 - val_loss: 0.4037 - val_AUC: 0.7834\n",
      "Epoch 6/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.3943 - AUC: 0.7960 - val_loss: 0.4033 - val_AUC: 0.7834\n",
      "Epoch 7/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3930 - AUC: 0.7971 - val_loss: 0.4031 - val_AUC: 0.7831\n",
      "folds 1 is done, score is 0.7832072990286207\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/10\n",
      "480000/480000 [==============================] - 3s 6us/sample - loss: 0.5099 - AUC: 0.5604 - val_loss: 0.4478 - val_AUC: 0.7494\n",
      "Epoch 2/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.4214 - AUC: 0.7692 - val_loss: 0.4105 - val_AUC: 0.7787\n",
      "Epoch 3/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4019 - AUC: 0.7893 - val_loss: 0.4051 - val_AUC: 0.7827\n",
      "Epoch 4/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.3970 - AUC: 0.7936 - val_loss: 0.4037 - val_AUC: 0.7833\n",
      "Epoch 5/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.3946 - AUC: 0.7957 - val_loss: 0.4032 - val_AUC: 0.7833\n",
      "Epoch 6/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.3930 - AUC: 0.7971 - val_loss: 0.4030 - val_AUC: 0.7830\n",
      "Epoch 7/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.3919 - AUC: 0.7981 - val_loss: 0.4030 - val_AUC: 0.7827\n",
      "folds 2 is done, score is 0.7827803931341122\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/10\n",
      "480000/480000 [==============================] - 3s 6us/sample - loss: 0.5047 - AUC: 0.5746 - val_loss: 0.4396 - val_AUC: 0.7567\n",
      "Epoch 2/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4165 - AUC: 0.7733 - val_loss: 0.4083 - val_AUC: 0.7799\n",
      "Epoch 3/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.4004 - AUC: 0.7906 - val_loss: 0.4044 - val_AUC: 0.7822\n",
      "Epoch 4/10\n",
      "480000/480000 [==============================] - 2s 3us/sample - loss: 0.3962 - AUC: 0.7943 - val_loss: 0.4034 - val_AUC: 0.7826\n",
      "Epoch 5/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3941 - AUC: 0.7960 - val_loss: 0.4031 - val_AUC: 0.7823\n",
      "Epoch 6/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3927 - AUC: 0.7974 - val_loss: 0.4029 - val_AUC: 0.7823\n",
      "folds 3 is done, score is 0.7823051974779471\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/10\n",
      "480000/480000 [==============================] - 3s 6us/sample - loss: 0.5024 - AUC: 0.5804 - val_loss: 0.4363 - val_AUC: 0.7600\n",
      "Epoch 2/10\n",
      "480000/480000 [==============================] - 1s 3us/sample - loss: 0.4138 - AUC: 0.7758 - val_loss: 0.4079 - val_AUC: 0.7804\n",
      "Epoch 3/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3994 - AUC: 0.7913 - val_loss: 0.4045 - val_AUC: 0.7824\n",
      "Epoch 4/10\n",
      "480000/480000 [==============================] - 2s 5us/sample - loss: 0.3956 - AUC: 0.7946 - val_loss: 0.4038 - val_AUC: 0.7823\n",
      "Epoch 5/10\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3936 - AUC: 0.7964 - val_loss: 0.4036 - val_AUC: 0.7821\n",
      "folds 4 is done, score is 0.7821357944509547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7826533289826314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(x=[idx, val],\n",
    "       y=y_train, \n",
    "       metrics_func=roc_auc_score,\n",
    "       split_method=StratifiedKFold,\n",
    "       fit_params=fit_param,\n",
    "       eval_param={'batch_size': batch_size},\n",
    "       use_proba=False, \n",
    "       verbose=True,\n",
    "       fit_use_valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/200\n",
      "480000/480000 [==============================] - 3s 6us/sample - loss: 0.3950 - AUC: 0.7960 - val_loss: 0.4044 - val_AUC: 0.7828\n",
      "Epoch 2/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3950 - AUC: 0.7960 - val_loss: 0.4044 - val_AUC: 0.7828\n",
      "Epoch 3/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3949 - AUC: 0.7960 - val_loss: 0.4043 - val_AUC: 0.7828\n",
      "Epoch 4/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3949 - AUC: 0.7960 - val_loss: 0.4043 - val_AUC: 0.7828\n",
      "Epoch 5/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3948 - AUC: 0.7961 - val_loss: 0.4043 - val_AUC: 0.7829\n",
      "Epoch 6/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3948 - AUC: 0.7961 - val_loss: 0.4043 - val_AUC: 0.7829\n",
      "Epoch 7/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3947 - AUC: 0.7961 - val_loss: 0.4042 - val_AUC: 0.7829\n",
      "Epoch 8/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3947 - AUC: 0.7961 - val_loss: 0.4042 - val_AUC: 0.7829\n",
      "Epoch 9/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3946 - AUC: 0.7962 - val_loss: 0.4042 - val_AUC: 0.7829\n",
      "Epoch 10/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3946 - AUC: 0.7962 - val_loss: 0.4042 - val_AUC: 0.7829\n",
      "Epoch 11/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3946 - AUC: 0.7962 - val_loss: 0.4041 - val_AUC: 0.7829\n",
      "Epoch 12/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3945 - AUC: 0.7962 - val_loss: 0.4041 - val_AUC: 0.7829\n",
      "Epoch 13/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3945 - AUC: 0.7962 - val_loss: 0.4041 - val_AUC: 0.7829\n",
      "Epoch 14/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3944 - AUC: 0.7962 - val_loss: 0.4041 - val_AUC: 0.7829\n",
      "folds 0 is done, score is 0.7829645524849089\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/200\n",
      "480000/480000 [==============================] - 3s 6us/sample - loss: 0.3915 - AUC: 0.7990 - val_loss: 0.4031 - val_AUC: 0.7831\n",
      "Epoch 2/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3915 - AUC: 0.7990 - val_loss: 0.4031 - val_AUC: 0.7831\n",
      "Epoch 3/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3914 - AUC: 0.7990 - val_loss: 0.4031 - val_AUC: 0.7831\n",
      "Epoch 4/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3914 - AUC: 0.7990 - val_loss: 0.4031 - val_AUC: 0.7832\n",
      "Epoch 5/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3914 - AUC: 0.7990 - val_loss: 0.4031 - val_AUC: 0.7832\n",
      "Epoch 6/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3914 - AUC: 0.7990 - val_loss: 0.4031 - val_AUC: 0.7831\n",
      "Epoch 7/200\n",
      "480000/480000 [==============================] - 2s 5us/sample - loss: 0.3913 - AUC: 0.7990 - val_loss: 0.4031 - val_AUC: 0.7831\n",
      "folds 1 is done, score is 0.7832149572335567\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/200\n",
      "480000/480000 [==============================] - 3s 7us/sample - loss: 0.3903 - AUC: 0.8001 - val_loss: 0.4030 - val_AUC: 0.7827\n",
      "Epoch 2/200\n",
      "480000/480000 [==============================] - 2s 5us/sample - loss: 0.3903 - AUC: 0.8001 - val_loss: 0.4030 - val_AUC: 0.7827\n",
      "Epoch 3/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3903 - AUC: 0.8001 - val_loss: 0.4030 - val_AUC: 0.7827\n",
      "Epoch 4/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3903 - AUC: 0.8001 - val_loss: 0.4030 - val_AUC: 0.7827\n",
      "Epoch 5/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3902 - AUC: 0.8001 - val_loss: 0.4030 - val_AUC: 0.7827\n",
      "Epoch 6/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3902 - AUC: 0.8001 - val_loss: 0.4030 - val_AUC: 0.7827\n",
      "folds 2 is done, score is 0.7827846327394261\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/200\n",
      "480000/480000 [==============================] - 3s 6us/sample - loss: 0.3910 - AUC: 0.7994 - val_loss: 0.4029 - val_AUC: 0.7822\n",
      "Epoch 2/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3910 - AUC: 0.7994 - val_loss: 0.4029 - val_AUC: 0.7822\n",
      "Epoch 3/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3910 - AUC: 0.7994 - val_loss: 0.4029 - val_AUC: 0.7822\n",
      "Epoch 4/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3909 - AUC: 0.7995 - val_loss: 0.4029 - val_AUC: 0.7822\n",
      "Epoch 5/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3909 - AUC: 0.7995 - val_loss: 0.4029 - val_AUC: 0.7823\n",
      "Epoch 6/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3909 - AUC: 0.7995 - val_loss: 0.4029 - val_AUC: 0.7823\n",
      "Epoch 7/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3909 - AUC: 0.7995 - val_loss: 0.4029 - val_AUC: 0.7823\n",
      "folds 3 is done, score is 0.7822922990737937\n",
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/200\n",
      "480000/480000 [==============================] - 3s 7us/sample - loss: 0.3918 - AUC: 0.7987 - val_loss: 0.4036 - val_AUC: 0.7821\n",
      "Epoch 2/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3917 - AUC: 0.7987 - val_loss: 0.4035 - val_AUC: 0.7821\n",
      "Epoch 3/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3917 - AUC: 0.7987 - val_loss: 0.4035 - val_AUC: 0.7821\n",
      "Epoch 4/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3917 - AUC: 0.7987 - val_loss: 0.4035 - val_AUC: 0.7821\n",
      "Epoch 5/200\n",
      "480000/480000 [==============================] - 2s 4us/sample - loss: 0.3916 - AUC: 0.7987 - val_loss: 0.4035 - val_AUC: 0.7821\n",
      "folds 4 is done, score is 0.7821688546554154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7826850592374202"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit param\n",
    "batch_size = 8192\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', patience=2, mode='max')\n",
    "fit_param = {'batch_size': batch_size,\n",
    "             'epochs':200,\n",
    "             'verbose': 1, \n",
    "             'callbacks':[callback]}\n",
    "\n",
    "# model_param\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "\n",
    "model = cv.model\n",
    "for i in model:\n",
    "    i.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(), metrics=['AUC'])\n",
    "    \n",
    "cv = CV(model, 5)\n",
    "\n",
    "cv.fit(x=[idx, val],\n",
    "       y=y_train, \n",
    "       metrics_func=roc_auc_score,\n",
    "       split_method=StratifiedKFold,\n",
    "       fit_params=fit_param,\n",
    "       eval_param={'batch_size': batch_size},\n",
    "       use_proba=False, \n",
    "       verbose=True,\n",
    "       fit_use_valid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit param\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', patience=2, mode='max')\n",
    "fit_param = {'batch_size': 4096, 'epochs':200, 'verbose': 0, 'callbacks':[callback]}\n",
    "\n",
    "cv_fit_param = {'fit_params': fit_param, \n",
    "                'eval_param': {'batch_size':4096},\n",
    "                'use_proba':False, \n",
    "                'fit_use_valid': True}\n",
    "\n",
    "# model_fix_param & model_search_space\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model_fix_param = {'vocabulary_size':ecd.get_vocabulary(), \n",
    "                   'feature_number': len(feature_col),\n",
    "                   'activation': 'sigmoid',\n",
    "                   'metrics': ['AUC'],\n",
    "                   'optimizer': opt, \n",
    "                   'k': 10}\n",
    "\n",
    "model_search_space = {'loss': hp.choice('loss', ['MSE', tf.keras.losses.BinaryCrossentropy()]),\n",
    "                      'l1': hp.loguniform('l1', -10, 0),\n",
    "                      'l2': hp.loguniform('l2', -10, 0)}\n",
    "\n",
    "# cv get score\n",
    "def neg_auc(y_true, y_pred):\n",
    "    return - roc_auc_score(y_true, y_pred)\n",
    "\n",
    "gs = CVGetScore(x=[idx, val],\n",
    "                y=y_train, \n",
    "                metrics_func=neg_auc,\n",
    "                split_method=StratifiedKFold,\n",
    "                nfolds=5, \n",
    "                random_state=2333,\n",
    "                model=fm, \n",
    "                cv_fit_params=cv_fit_param, \n",
    "                model_fix_params=model_fix_param, \n",
    "                model_search_space=model_search_space)\n",
    "\n",
    "tuning = Tuning(gs, verbose=1)\n",
    "tuning.fmin(gs.GET_SEARCH_SPACE(), max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "model = linear_regression(vocabulary_size=ecd.get_vocabulary(), \n",
    "                          feature_number=len(feature_col),, \n",
    "                          activation='sigmoid',\n",
    "                          loss='mse',\n",
    "                          metrics=['AUC'],\n",
    "                          optimizer=opt, \n",
    "                          l1=0., l2=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_AUC', patience=5, mode='max')\n",
    "fit_param = {'batch_size':1024, 'epochs':20, 'verbose': 1, 'callbacks':[callback]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_param = {'batch_size':1024}\n",
    "\n",
    "cv = CV(model, 5)\n",
    "\n",
    "cv.fit(x=[idx, val],\n",
    "       y=y_train, \n",
    "       metrics_func=roc_auc_score,\n",
    "       split_method=StratifiedKFold,\n",
    "       fit_params=fit_param,\n",
    "       eval_param=pred_param,\n",
    "       use_proba=False, \n",
    "       verbose=True,\n",
    "       fit_use_valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
